{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T # for simplifying the transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torchvision import models\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'] 10\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../Data\"\n",
    "classes = get_classes(dataset_path + \"/train\" + \"/images_original\")\n",
    "print(classes, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000.1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000.2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00000.3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00000.4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.003521             1773.065032          167541.630869   \n",
       "1  0.001450             1816.693777           90525.690866   \n",
       "2  0.004620             1788.539719          111407.437613   \n",
       "3  0.002448             1655.289045          111952.284517   \n",
       "4  0.001701             1630.656199           79667.267654   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              1972.744388           117335.771563  ...   39.687145   \n",
       "1              2010.051501            65671.875673  ...   64.748276   \n",
       "2              2084.565132            75124.921716  ...   67.336563   \n",
       "3              1960.039988            82913.639269  ...   47.739452   \n",
       "4              1948.503884            60204.020268  ...   30.336359   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
       "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
       "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
       "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
       "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0    -0.243027   43.771767  blues  \n",
       "1     5.784063   59.943081  blues  \n",
       "2     2.517375   33.105122  blues  \n",
       "3     3.630866   32.023678  blues  \n",
       "4     0.536961   29.146694  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataset_path}/features_3_sec.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 800 training images.\n",
      "There are 100 validation images.\n",
      "There are 99 test images.\n"
     ]
    }
   ],
   "source": [
    "train_filenames, val_filenames, test_filenames = [], [], []\n",
    "train_path = os.path.join(dataset_path, \"train\", \"genres_original\")\n",
    "val_path = os.path.join(dataset_path, \"val\", \"genres_original\")\n",
    "test_path = os.path.join(dataset_path, \"test\", \"genres_original\")\n",
    "\n",
    "# Iterate through all the files in the train, val, test directories and put them in their respective lists\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    for name in files:\n",
    "        train_filenames.append(name)\n",
    "\n",
    "print(f'There are {len(train_filenames)} training images.')\n",
    "\n",
    "for root, dirs, files in os.walk(val_path):\n",
    "    for name in files:\n",
    "        val_filenames.append(name)\n",
    "\n",
    "print(f'There are {len(val_filenames)} validation images.')\n",
    "\n",
    "for root, dirs, files in os.walk(test_path):\n",
    "    for name in files:\n",
    "        test_filenames.append(name)\n",
    "\n",
    "print(f'There are {len(test_filenames)} test images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7993 training features.\n",
      "There are 999 validation features.\n",
      "There are 988 test features.\n"
     ]
    }
   ],
   "source": [
    "# Go through the filenames in column \"filename\" \n",
    "# and if it can be found in train_filenames, val_filenames or test_filenames,\n",
    "# then put the corresponding path in the column \"path\"\n",
    "train_features_3_sec = pd.DataFrame(columns=df.columns)\n",
    "val_features_3_sec = pd.DataFrame(columns=df.columns)\n",
    "test_features_3_sec = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    splits = row['filename'].split('.')\n",
    "    row['filename'] = splits[0] + \".\" + splits[1] + \".\" + splits[3] \n",
    "    if row['filename'] in train_filenames:\n",
    "        new_df = pd.DataFrame([row], columns=df.columns)\n",
    "        train_features_3_sec = pd.concat([train_features_3_sec, new_df], ignore_index=True)\n",
    "    elif row['filename'] in val_filenames:\n",
    "        new_df = pd.DataFrame([row], columns=df.columns)\n",
    "        val_features_3_sec = pd.concat([val_features_3_sec, new_df], ignore_index=True)\n",
    "    elif row['filename'] in test_filenames:\n",
    "        new_df = pd.DataFrame([row], columns=df.columns)\n",
    "        test_features_3_sec = pd.concat([test_features_3_sec, new_df], ignore_index=True)\n",
    "\n",
    "train_features_3_sec.to_csv(f'{dataset_path}/train_features_3_sec.csv', index=False)\n",
    "val_features_3_sec.to_csv(f'{dataset_path}/val_features_3_sec.csv', index=False)\n",
    "test_features_3_sec.to_csv(f'{dataset_path}/test_features_3_sec.csv', index=False)\n",
    "\n",
    "print(f'There are {len(train_features_3_sec)} training features.')\n",
    "print(f'There are {len(val_features_3_sec)} validation features.')\n",
    "print(f'There are {len(test_features_3_sec)} test features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply xgboost to the dataset\n",
    "df = pd.read_csv(f'{dataset_path}/train_features_3_sec.csv')\n",
    "\n",
    "genre_list = df.iloc[:, -1]\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df = df.iloc[0:, 1:] \n",
    "\n",
    "# Create a target variable 'y' by selecting the 'label' column from the DataFrame\n",
    "y_train = encoder.fit_transform(genre_list)\n",
    "\n",
    "# Create a feature matrix 'X' by selecting all columns from the DataFrame except 'label'\n",
    "X_train = df.loc[:, df.columns != 'label']\n",
    "\n",
    "# Normalize the feature matrix 'X' using Min-Max scaling\n",
    "cols = X_train.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dataset_path}/val_features_3_sec.csv')\n",
    "\n",
    "genre_list = df.iloc[:, -1]\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df = df.iloc[0:, 1:] \n",
    "\n",
    "# Create a target variable 'y' by selecting the 'label' column from the DataFrame\n",
    "y_val = encoder.fit_transform(genre_list)\n",
    "\n",
    "# Create a feature matrix 'X' by selecting all columns from the DataFrame except 'label'\n",
    "X_val = df.loc[:, df.columns != 'label']\n",
    "\n",
    "# Normalize the feature matrix 'X' using Min-Max scaling\n",
    "cols = X_val.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X_val)\n",
    "X_val = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dataset_path}/test_features_3_sec.csv')\n",
    "\n",
    "genre_list = df.iloc[:, -1]\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df = df.iloc[0:, 1:] \n",
    "\n",
    "# Create a target variable 'y' by selecting the 'label' column from the DataFrame\n",
    "y_test = encoder.fit_transform(genre_list)\n",
    "\n",
    "# Create a feature matrix 'X' by selecting all columns from the DataFrame except 'label'\n",
    "X_test = df.loc[:, df.columns != 'label']\n",
    "\n",
    "# Normalize the feature matrix 'X' using Min-Max scaling\n",
    "cols = X_test.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assess(X_train, y_train, X_test, y_test, model, title = \"Default\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test.values)\n",
    "    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9991, 58) (9991,)\n",
      "(988, 58) (988,)\n",
      "Accuracy Cross Gradient Booster : 0.47368 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbmodel = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
    "X_train = pd.concat([X_train, X_val], ignore_index=True)\n",
    "y_train = np.concatenate((y_train, y_val), axis=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "model_assess(X_train, y_train, X_test, y_test, xgbmodel, \"Cross Gradient Booster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size):\n",
    "    transform = T.Compose([ # We dont need augmentation for test transforms\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n",
    "    ])\n",
    "    test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/images_original/\"), transform=transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return test_loader, len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_loader, test_data_len) = get_data_loaders(dataset_path, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_swin_transformer_model(hub_url, model_name, num_classes, device, checkpoint_path=None):\n",
    "    # Load pre-trained Swin Transformer model\n",
    "    model = torch.hub.load(hub_url, model_name, pretrained=True)\n",
    "    \n",
    "    # Freeze the model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Modify the model head\n",
    "    n_inputs = model.head.in_features\n",
    "    model.head = nn.Sequential(\n",
    "        nn.Linear(n_inputs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize criterion, optimizer, and scheduler\n",
    "    criterion = LabelSmoothingCrossEntropy()\n",
    "    criterion = criterion.to(device)\n",
    "    optimizer = optim.Adam(model.head.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_acc = checkpoint['best_acc']\n",
    "        train_losses = checkpoint['train_losses']\n",
    "        train_accuracies = checkpoint['train_accuracies']\n",
    "        val_losses = checkpoint['val_losses']\n",
    "        val_accuracies = checkpoint['val_accuracies']\n",
    "\n",
    "    return model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sanyam/.cache/torch/hub/SharanSMenon_swin-transformer-hub_main\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"../Models/SwinT/_epoch_49.pth\"\n",
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "swin_model, _, _, _ = load_swin_transformer_model(\n",
    "    hub_url = HUB_URL,\n",
    "    model_name = MODEL_NAME,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    num_classes=len(classes),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of blues: 50% ( 5/10)\n",
      "Test Accuracy of classical: 100% (10/10)\n",
      "Test Accuracy of country: 80% ( 8/10)\n",
      "Test Accuracy of disco: 30% ( 3/10)\n",
      "Test Accuracy of hiphop: 80% ( 8/10)\n",
      "Test Accuracy of  jazz: 88% ( 8/ 9)\n",
      "Test Accuracy of metal: 90% ( 9/10)\n",
      "Test Accuracy of   pop: 80% ( 8/10)\n",
      "Test Accuracy of reggae: 90% ( 9/10)\n",
      "Test Accuracy of  rock: 57% ( 4/ 7)\n",
      "Test Accuracy of 75% (72/96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0 for i in range(len(classes)))\n",
    "class_total = list(0 for i in range(len(classes)))\n",
    "swin_model.eval()\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        output = swin_model(data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    if len(target) == 32:\n",
    "        for i in range(32):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
    "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
    "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
    "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders_2(data_dir, batch_size, train=False):\n",
    "    test_transforms = Compose([\n",
    "        ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4931, 0.9151, 0.9960], std=[\n",
    "                             0.4495, 0.1716, 0.0602])\n",
    "    ])\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test/images_original/\"), transform=test_transforms)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    return test_dataloader, len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_loader, test_data_len) = get_data_loaders_2(dataset_path, 32, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet18_model(checkpoint_path, classes, device):\n",
    "    # Load a Pretrained ResNet18 Model\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    in_features = resnet.fc.in_features\n",
    "    fc = nn.Linear(in_features=in_features, out_features=len(classes))\n",
    "    resnet.fc = fc\n",
    "    resnet = resnet.to(device)\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # Restore the model state\n",
    "    resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # If you need to continue training, also restore the optimizer state\n",
    "    optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Other data from the checkpoint, if needed\n",
    "    train_losses = checkpoint.get('train_losses', [])\n",
    "    val_losses = checkpoint.get('val_losses', [])\n",
    "\n",
    "    return resnet, optimizer, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../Models/Resnet18/checkpoint_50.pth\"\n",
    "resnet18_model, optimizer, train_losses, val_losses = load_resnet18_model(checkpoint_path, classes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of blues : 30.00 %\n",
      "Accuracy of classical : 70.00 %\n",
      "Accuracy of country : 50.00 %\n",
      "Accuracy of disco : 50.00 %\n",
      "Accuracy of hiphop : 70.00 %\n",
      "Accuracy of jazz : 88.89 %\n",
      "Accuracy of metal : 60.00 %\n",
      "Accuracy of pop : 80.00 %\n",
      "Accuracy of reggae : 30.00 %\n",
      "Accuracy of rock : 60.00 %\n",
      "Accuracy: 58.58585858585859\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate through the test dataloader\n",
    "for img, label in test_loader:\n",
    "    img = img.to(device)\n",
    "    resnet18_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = resnet18_model(img)\n",
    "    \n",
    "    final_preds = torch.max(prediction, dim=1)[1]\n",
    "    y_test.extend(label.tolist())\n",
    "    y_pred.extend(final_preds.cpu().tolist())\n",
    "\n",
    "# Map predicted indices back to class names\n",
    "y_pred_labels = [classes[pred] for pred in y_pred]\n",
    "\n",
    "# Calculate class-wise accuracy\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "classwise_accuracy = {}\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    label = y_test[i]\n",
    "    pred = y_pred[i]\n",
    "    if label == pred:\n",
    "        class_correct[label] += 1\n",
    "    class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    classwise_accuracy[classes[i]] = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "\n",
    "# Print Class-wise accuracy\n",
    "for class_name, accuracy in classwise_accuracy.items():\n",
    "    print(f'Accuracy of {class_name} : {accuracy:.2f} %')\n",
    "\n",
    "print(\"Accuracy:\",(100*(np.array(y_test) == np.array(y_pred)).sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def weighted_ensemble_predictions(resnet_model, swin_model, resnet_loader, swin_loader, device, resnet_weight=0.3, swin_weight=0.7):\n",
    "    assert resnet_weight + swin_weight == 1, \"Weights must sum up to 1.\"\n",
    "\n",
    "    resnet_model.eval()\n",
    "    swin_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (resnet_batch, swin_batch) in zip(resnet_loader, swin_loader):\n",
    "            resnet_inputs, labels = resnet_batch\n",
    "            swin_inputs, _ = swin_batch\n",
    "\n",
    "            resnet_inputs, swin_inputs = resnet_inputs.to(device), swin_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get predictions from both models\n",
    "            outputs_resnet = nn.functional.softmax(resnet_model(resnet_inputs), dim=1)\n",
    "            outputs_swin = nn.functional.softmax(swin_model(swin_inputs), dim=1)\n",
    "\n",
    "            # Weighted average of outputs\n",
    "            averaged_outputs = (outputs_resnet * resnet_weight) + (outputs_swin * swin_weight)\n",
    "\n",
    "            # Final prediction\n",
    "            _, preds = torch.max(averaged_outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
    "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "dataset_path = \"../Data\"\n",
    "\n",
    "# Example usage\n",
    "swin_dataloader, _ = get_data_loaders(dataset_path, batch_size)\n",
    "resnet_dataloader, _ = get_data_loaders_2(dataset_path, batch_size)\n",
    "\n",
    "predictions, labels = weighted_ensemble_predictions(resnet18_model, swin_model, resnet_dataloader, swin_dataloader, device, resnet_weight=0.2, swin_weight=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for blues: 0.60\n",
      "Accuracy for classical: 1.00\n",
      "Accuracy for country: 0.80\n",
      "Accuracy for disco: 0.40\n",
      "Accuracy for hiphop: 0.80\n",
      "Accuracy for jazz: 0.89\n",
      "Accuracy for metal: 0.90\n",
      "Accuracy for pop: 0.80\n",
      "Accuracy for reggae: 0.90\n",
      "Accuracy for rock: 0.50\n",
      "Accuracy: 75.75757575757575\n"
     ]
    }
   ],
   "source": [
    "def per_class_accuracy(predictions, labels, class_names):\n",
    "    \"\"\"\n",
    "    Compute per-class accuracy given predictions and labels.\n",
    "\n",
    "    :param predictions: List or array of model predictions.\n",
    "    :param labels: List or array of ground truth labels.\n",
    "    :param class_names: List of class names.\n",
    "    :return: Dictionary of per-class accuracy.\n",
    "    \"\"\"\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    # Calculate per-class accuracies\n",
    "    class_accuracies = {}\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if i < len(cm):\n",
    "            true_positives = cm[i, i]\n",
    "            total = sum(cm[i, :])\n",
    "            class_accuracy = true_positives / total if total > 0 else 0\n",
    "            class_accuracies[class_name] = class_accuracy\n",
    "    \n",
    "    return class_accuracies\n",
    "\n",
    "# Example usage\n",
    "class_accuracies = per_class_accuracy(predictions, labels, classes)\n",
    "\n",
    "for class_name, accuracy in class_accuracies.items():\n",
    "    print(f\"Accuracy for {class_name}: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Accuracy:\",(100*(np.array(labels) == np.array(predictions)).sum()/len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_by_both: 50\n",
      "correct_by_resnet_only: 8\n",
      "correct_by_swin_only: 23\n",
      "incorrect_by_both: 18\n",
      "total_samples: 99\n"
     ]
    }
   ],
   "source": [
    "def prediction_analysis(resnet_model, swin_model, resnet_loader, swin_loader, device):\n",
    "    resnet_model.eval()\n",
    "    swin_model.eval()\n",
    "\n",
    "    correct_by_both = 0\n",
    "    correct_by_resnet_only = 0\n",
    "    correct_by_swin_only = 0\n",
    "    incorrect_by_both = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (resnet_batch, swin_batch) in zip(resnet_loader, swin_loader):\n",
    "            resnet_inputs, labels = resnet_batch\n",
    "            swin_inputs, _ = swin_batch\n",
    "\n",
    "            # Move to device\n",
    "            resnet_inputs, swin_inputs, labels = resnet_inputs.to(device), swin_inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            outputs_resnet = resnet_model(resnet_inputs)\n",
    "            outputs_swin = swin_model(swin_inputs)\n",
    "\n",
    "            _, preds_resnet = torch.max(outputs_resnet, 1)\n",
    "            _, preds_swin = torch.max(outputs_swin, 1)\n",
    "\n",
    "            # Update counts\n",
    "            correct_resnet = (preds_resnet == labels)\n",
    "            correct_swin = (preds_swin == labels)\n",
    "\n",
    "            correct_by_both += torch.sum(correct_resnet & correct_swin).item()\n",
    "            correct_by_resnet_only += torch.sum(correct_resnet & ~correct_swin).item()\n",
    "            correct_by_swin_only += torch.sum(~correct_resnet & correct_swin).item()\n",
    "            incorrect_by_both += torch.sum(~correct_resnet & ~correct_swin).item()\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    return {\n",
    "        \"correct_by_both\": correct_by_both,\n",
    "        \"correct_by_resnet_only\": correct_by_resnet_only,\n",
    "        \"correct_by_swin_only\": correct_by_swin_only,\n",
    "        \"incorrect_by_both\": incorrect_by_both,\n",
    "        \"total_samples\": total_samples\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "analysis_results = prediction_analysis(resnet18_model, swin_model, resnet_dataloader, swin_dataloader, device)\n",
    "\n",
    "for key, value in analysis_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
